{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "For the first few parts, we take the results scraped on Mar 10 to perform exploration on the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import wordcloud\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/video_clean.csv', thousands = ',', encoding = 'utf-8')\n",
    "data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency of Words / Tokens \n",
    "\n",
    "We combine all the tokens in titles and count the frequency of the key words at one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = data.clean_text.str.split().copy()\n",
    "\n",
    "#string = string.str.lower()\n",
    "# np.append(string[1],string[2])\n",
    "text = []\n",
    "for i in range(len(data.title.values)):\n",
    "    text = text + string[i]\n",
    "text[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 30 most frequent tokens is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count1 = Counter(text)\n",
    "\n",
    "most_c = count1.most_common().copy()\n",
    "most_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Coronavirus\" has the highest frequency(since we searched by it), followed by the \"News\", \"Outbreak\", and \"China\". As the event develops, the ranking will probably change. We will look at this in the later sections.\n",
    "\n",
    "We removed single letter from the tokens since it had no meanings, but we did not easily remove two-letter tokens from the list because it may be confused with abbrevations.\\\n",
    "Such as: `LA`(Los Angeles) and `la` (Spanish, the)\n",
    "\n",
    "Obviously there was some Spanish and other language mixing in the token set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in reversed(range(0,len(most_c)-1)):\n",
    "    if len(most_c[i][0]) == 1:\n",
    "        print(most_c[i],i)\n",
    "        most_c.remove(most_c[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in reversed(range(0,len(most_c)-1)):\n",
    "    if len(most_c[i][0]) == 2:\n",
    "        print(most_c[i],i)\n",
    "most_c.remove(most_c[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_c_50 = most_c[1:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `Coronavirus` had the highest frequency. We focus on the frequency of other tokens except the word `coronavirus` in future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,15))\n",
    "names, values = zip(*most_c_50)  \n",
    "plt.barh(names,values)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channels vs. Subscribers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data[['channel','subscriber']].copy()\n",
    "data1 = data1.drop_duplicates().copy()\n",
    "data1 = data1.sort_values(by='subscriber',ascending = False).copy()\n",
    "data1[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 10 results are shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.barh(data1.channel[0:10],data1.subscriber[0:10])\n",
    "plt.xlabel('Subscribers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed the variety of uploaders, this includes:\n",
    "* Traditional International News Stations\n",
    "* Personal vlogger ('Luisito Comunica')\n",
    "* New Media\n",
    "* Talk shows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channels vs. Views\n",
    "Who gain the most number of views on videos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data[['channel','view']].copy()\n",
    "data1 = data1.drop_duplicates().copy()\n",
    "data1 = data1.sort_values(by='view',ascending = False).copy()\n",
    "data1[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed channels that gain the most views had a variety, concentrating on:\n",
    "* Self-Media (Doctor Mike)\n",
    "* Local and International News Stations (ABC, CNN, Guardian)\n",
    "* Talk Shows (Last Week Tonight, SNL, Daily Show)\n",
    "\n",
    "Talk shows may be easier to attract more views."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who post the most number of videos about coronavirus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first 30 uploaders, based on the first scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "data['channel1'] = 'Others'\n",
    "\n",
    "data['channel'].values\n",
    "\n",
    "data['channel'].value_counts()[0:30].index\n",
    "\n",
    "for i in range(len(data['channel'].values)-1): # process data to make the plot readable\n",
    "    if data.loc[i,'channel'] in data['channel'].value_counts()[0:30].index:\n",
    "        data.loc[i,'channel1'] = data.loc[i,'channel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,11))\n",
    "data['channel1'].value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed that US News stations and international news stations posted a large proportion of videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who provided the contents with longest duration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_len = data.groupby('channel', as_index=False).agg({\"length\": \"sum\"}).copy()\n",
    "tot_len = tot_len.sort_values('length',ascending = False)\n",
    "tot_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.barh(tot_len['channel'][0:20],tot_len['length'][0:20])\n",
    "plt.xlabel('Length of Videos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extremely long videos are mostly playbacks of live stream.\n",
    "* This ranking is different from the list subscribers and views. We suspected that the attractiveness to watch videos might have something to do with the channels and number subscribers as the quality or the contents of videos varied. Also, the recommendation system of the search engine might also affected the number of views."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trend of Views at Different Time\n",
    "\n",
    "For a specific video, we are interested in the how the view increase with time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* since we have a list of search results in the time range, we can see the temporal change of the video views, likes and so on. Since the increase rate of different videos might be totally different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"../data/clean/*.csv\")\n",
    "files = [i.split('/')[3] for i in filenames]\n",
    "filenamelist = [i.split('.')[0] for i in files]\n",
    "filenamelist = np.sort(filenamelist)\n",
    "filenamelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '../data/clean/'+ filenamelist[-1] + '.csv'\n",
    "videodata = pd.read_csv(name, thousands = ',', encoding = 'utf-8')\n",
    "videodata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most viewed video title\n",
    "title = videodata.loc[videodata['view'].idxmax(),'clean_text']\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(videodata.columns)\n",
    "columns.append('filetime')\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = pd.DataFrame(columns = columns)\n",
    "for i in filenamelist:\n",
    "    name = '../data/clean/'+ i + '.csv'\n",
    "    videodata = pd.read_csv(name, thousands = ',', encoding = 'utf-8')\n",
    "    sample = videodata[videodata['clean_text']==title]\n",
    "    if len(sample) == 0:\n",
    "        print(i)\n",
    "        continue\n",
    "        \n",
    "    date = int(i.split('_')[1][2:4]) #date\n",
    "    hour = int(i.split('_')[2][0:2])\n",
    "    minute = int(i.split('_')[2][2:4])\n",
    "\n",
    "    time = (date-12)*24 + hour + minute/60\n",
    "    sample = sample.assign(filetime = [time]) \n",
    "    videos = videos.append(sample)\n",
    "videos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(videos['view'].values.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logview = np.log(videos['view'].values.astype(int))\n",
    "like = (videos['like'].values.astype(int))\n",
    "likeoview = (videos['like'].values.astype(int))/(videos['view'].values.astype(int))\n",
    "plt.scatter(videos['filetime'].values,logview, alpha=0.5)\n",
    "#plt.scatter(videos['filetime'].values,likeoview, alpha=0.5)\n",
    "            \n",
    "plt.title('Change of views over time', size=13)\n",
    "plt.xlabel('Time in hour', size=10)\n",
    "plt.ylabel('Counts', size=10)\n",
    "#plt.legend(labels=['views','likes'])                           \n",
    "                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This figure shows the number of view over time (in hour unit) of a certain video, named 'serious coronavirus infectious disease expert michael osterholm explains joe rogan'.\n",
    "It seems that the increase rate is approximately stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(videos['filetime'].values,like, alpha=0.5)\n",
    "\n",
    "            \n",
    "plt.title('Change of like over time', size=13)\n",
    "plt.xlabel('Time in hour', size=10)\n",
    "plt.ylabel('Counts', size=10)\n",
    "#plt.legend(labels=['views','likes'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see similar pattern for the increase of likes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(videos['filetime'].values,likeoview, alpha=0.5)\n",
    "\n",
    "            \n",
    "plt.title('Change of ratio of like over view over time', size=13)\n",
    "plt.xlabel('Time in hour', size=10)\n",
    "plt.ylabel('Counts', size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is not suprising is that the ratio of like over view (like ratio) is relatively stable, over the time. Meaning people have similar attitute towards the quality and content of the video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trend of Frequency of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordmap(datafilename):\n",
    "    \"\"\"\n",
    "    Produces a wordmap for each scraping.\n",
    "    \"\"\"\n",
    "    print(datafilename)\n",
    "    data2 = pd.read_csv(datafilename, thousands = ',', encoding = 'utf-8')\n",
    "    string2 = data2.clean_text.str.split().copy()\n",
    "    text2 = []\n",
    "    for i in range(len(data2.title.values)):\n",
    "        text2 = text2 + string2[i]\n",
    "\n",
    "    count2 = Counter(text2)\n",
    "    most_c_2 = count2.most_common().copy()\n",
    "    for i in reversed(range(0,len(most_c_2)-1)):\n",
    "        if len(most_c_2[i][0]) == 1:\n",
    "            # print(most_c_2[i],i)\n",
    "            most_c_2.remove(most_c_2[i])\n",
    "    wc2 = wordcloud.WordCloud(width = 1000,max_words=500, height = 500,background_color=\"white\",\n",
    "                              collocations = True,relative_scaling=0.2).generate_from_frequencies(dict(most_c_2[1:60]))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(wc2, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('First Scrape on March 10')\n",
    "wordmap('../data/video_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordmap('../data/clean/' + filenamelist[0]+ '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordmap('../data/clean/' + filenamelist[4]+ '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordmap('../data/clean/' + filenamelist[8]+ '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordmap('../data/clean/' + filenamelist[12]+ '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordmap('../data/clean/' + filenamelist[16]+ '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried to see how the event evolved in these days, from March 10 to March 15.\n",
    "* Most of the key words remained high frequency such as \"News\", \"Outbreak\" and \"COVID(-19)\". These word are essential parts of the titles of videos about coronavirus. \n",
    "* We noticed as Trump had more speeches and orders, the frequency of \"Trump\" generally increased. \n",
    "* As China had the pneumonia controlled, the frequency of \"China\" and \"Wuhan\" acturally decreased. \n",
    "* As the community spread become more severe in multiple positions in European countries and north America, we saw some new names of regions in the newer word maps.\n",
    "* Many regions declared state of \"Emergency\" so this token appeared."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
